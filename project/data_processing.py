# -*- coding: utf-8 -*-
"""Explorotary Data Analysis - Mortgage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ejzzflQenzZdFEVZwhZcvtDci7_ib1A7

# Explorotary Data Analysis for Rhode Island Dataset

Download the file here: https://drive.google.com/file/d/1cvA5Ed4Ujz98JAagq9oLh3pmHyqc3JzU/view?usp=sharing

Upload to your runtime environment when you run
"""

# Imports

from sklearn.impute import SimpleImputer
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


def process_data(df):
    """First, we need to identify how to pre-process the data. We want to categorize the derived ethnicity, race, and sex values. Furthermore, we need to convert datatypes of several columns, and fill in NaN values with different methods (calcuation, imputation, etc.). We also need to remove any duplicate rows. Lastly, we drop any outliers in our dataset (beyond 0.5% of the median)."""

    # select and re-order columns
    columns = ['county_code', 'derived_ethnicity', 'derived_race', 'derived_sex', 'action_taken', 'loan_type', 'loan_purpose', 'lien_status',
               'loan_amount', 'loan_to_value_ratio', 'interest_rate', 'property_value', 'occupancy_type', 'debt_to_income_ratio', 'applicant_age', 'rate_spread']
    df = df[columns]

    # find value counts by ethnicity
    df_ethnicity = df.value_counts(subset=["derived_ethnicity"])
    df_ethnicity

    # drop free form text only derived_ethnicity
    df = df[df['derived_ethnicity'] != 'Free Form Text Only']

    df_race = df.value_counts(subset="derived_race")
    df_race

    # drop free form text only derived_ethnicity
    df = df[df['derived_race'] != '2 or more minority races']

    df_sex = df.value_counts(subset="derived_sex")
    df_sex

    df.info()

    # categorize ethnicity, race, sex values
    df["derived_ethnicity"] = df["derived_ethnicity"].astype("category")
    df["derived_race"] = df["derived_race"].astype("category")
    df["derived_sex"] = df["derived_sex"].astype("category")
    df["applicant_age"] = df["applicant_age"].astype("category")

    df.columns

    # convert loan_to_value, interest_rate, property_value, debt_to_income, applicant_age to numeric
    df["loan_to_value_ratio"] = pd.to_numeric(
        df["loan_to_value_ratio"], errors="coerce")
    df["interest_rate"] = pd.to_numeric(df["interest_rate"], errors="coerce")
    df["property_value"] = pd.to_numeric(df["property_value"], errors="coerce")
    df["debt_to_income_ratio"] = pd.to_numeric(
        df["debt_to_income_ratio"], errors="coerce")
    df["rate_spread"] = pd.to_numeric(df["rate_spread"], errors="coerce")

    cols_to_check = [
        'derived_ethnicity', 'derived_race', 'derived_sex', 'action_taken',
        'loan_type', 'loan_purpose', 'lien_status', 'loan_amount',
        'occupancy_type', 'applicant_age', 'county_code'
    ]

    df = df.dropna(subset=cols_to_check)

    df_knn = df.copy()
    imp_cols = ['loan_type', 'loan_purpose', 'lien_status', 'loan_amount', 'loan_to_value_ratio',
                'interest_rate', 'property_value', 'occupancy_type', 'debt_to_income_ratio', 'rate_spread']
    imputer = SimpleImputer(strategy="median")
    out = imputer.fit_transform(df_knn[imp_cols])

    df[imp_cols] = out

    action_map = {1: 1, 2: 1, 8: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0}

    # Apply the mapping
    df['loan_approved'] = df['action_taken'].map(action_map)

    # Approval rate by race
    approval_by_race = df.groupby('derived_race')['loan_approved'].mean()

    # Approval rate by ethnicity
    approval_by_ethnicity = df.groupby('derived_ethnicity')[
        'loan_approved'].mean()

    # Approval rate by sex
    approval_by_sex = df.groupby('derived_sex')['loan_approved'].mean()

    # Display results
    print("Approval Rates by Race:")
    print(approval_by_race, "\n")

    print("Approval Rates by Ethnicity:")
    print(approval_by_ethnicity, "\n")

    print("Approval Rates by Sex:")
    print(approval_by_sex)

    # drop top 0.5% of all columns
    cols = ['loan_amount', 'loan_to_value_ratio',
            'interest_rate', 'property_value', 'debt_to_income_ratio']
    # Compute 99.5th percentiles for specified columns
    upper_limits = df[cols].quantile(0.995)
    # Compare only the relevant columns to their upper limits
    mask = (df[cols] <= upper_limits)
    # Keep rows where all selected columns are within limits
    df = df[mask.all(axis=1)]

    return df


if __name__ == '__main__':
    df = pd.read_csv("state_RI.csv")
    processed = process_data(df)
    processed.to_csv("processed_data.csv", index=False)
    print("Processed data saved to processed_data.csv")
