{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b726bb00-b714-4669-af10-b50df1a3a494",
   "metadata": {},
   "source": [
    "# Data Manipulation Methods and Exploratory Data Analysis\n",
    "\n",
    "Having a good BS meter for data is crucial to becoming a good data scientist.  Data tells a story, and the way you tell the story, the context you provide, and most importantly, the details you leave out can change the message the story conveys.  When in doubt, it is best to conduct an exhaustive analysis of the data you have.  In particular, to understand data fully, one often needs to conduct exploratory data analysis (EDA).  If a scientist has conducted thorough EDA on their data, the reliability and trust of their work increases as they qualify their results and communicate truth more than results that support their hypothesis.\n",
    "\n",
    "Although scientists can manipulate data in different ways, we will explore two ways with the following datasets: Berkeley admission data and health data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343972e-8bf0-40c2-b384-c53b5014222a",
   "metadata": {},
   "source": [
    "# Berkeley Admissions Data\n",
    "\n",
    "In this notebook, we will analyze graduate admissions data from UC Berkeley. To study this, we first import all relevant libraries, then we will consider if there seems to be unfair play with the admissions.  Let us begin with proper import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d89f51-f3bc-478c-9c47-ab93688be207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os # operating system\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce1bec3-3aec-47d6-891c-a52bfb074601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Major</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Admission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1973</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1973</td>\n",
       "      <td>Other</td>\n",
       "      <td>F</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973</td>\n",
       "      <td>Other</td>\n",
       "      <td>M</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1973</td>\n",
       "      <td>Other</td>\n",
       "      <td>M</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Major Gender Admission\n",
       "0  1973      C      F  Rejected\n",
       "1  1973      B      M  Accepted\n",
       "2  1973  Other      F  Accepted\n",
       "3  1973  Other      M  Accepted\n",
       "4  1973  Other      M  Rejected"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Berkeley admission data\n",
    "file_path = 'berkeley.csv'\n",
    "berkeley_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "berkeley_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c988b76-d9dd-4fed-821d-cce1b368131d",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "\n",
    "The dataset contains the following columns:\n",
    "- Year: The year of admission.\n",
    "- Major: The department or field of study.\n",
    "- Gender: The gender of the applicant.\n",
    "- Admission: Whether the applicant was \"Accepted\" or \"Rejected\".\n",
    "\n",
    "Let us calculate the overall admission rates for men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33081b97-5ed6-4264-b9dd-2609f1a8a354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Admission</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>Rejected</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1494</td>\n",
       "      <td>2827</td>\n",
       "      <td>4321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>3738</td>\n",
       "      <td>4704</td>\n",
       "      <td>8442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Admission  Accepted  Rejected  Total\n",
       "Gender                              \n",
       "F              1494      2827   4321\n",
       "M              3738      4704   8442"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the overall admission rates by gender\n",
    "### YOUR CODE HERE ###\n",
    "overall_admission = berkeley_data.groupby([\"Gender\", \"Admission\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# Display overall admission rates\n",
    "overall_admission[\"Total\"] = overall_admission.sum(axis=1)\n",
    "overall_admission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d08e1-3d73-45c2-aab3-c33875beb1fc",
   "metadata": {},
   "source": [
    "What do you notice?  Which gender seems to be favored more?  Are there any confounding variable that may be giving this result?  Please do some exploratory data analysis that will either support or reject the results from the previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2d209f-ec62-4c02-acfe-c4235247e68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admission</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>Rejected</th>\n",
       "      <th>Total</th>\n",
       "      <th>Admission Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">A</th>\n",
       "      <th>F</th>\n",
       "      <td>89</td>\n",
       "      <td>19</td>\n",
       "      <td>108</td>\n",
       "      <td>82.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>825</td>\n",
       "      <td>313</td>\n",
       "      <td>1138</td>\n",
       "      <td>72.495606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B</th>\n",
       "      <th>F</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>353</td>\n",
       "      <td>207</td>\n",
       "      <td>560</td>\n",
       "      <td>63.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">C</th>\n",
       "      <th>F</th>\n",
       "      <td>201</td>\n",
       "      <td>392</td>\n",
       "      <td>593</td>\n",
       "      <td>33.895447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>120</td>\n",
       "      <td>205</td>\n",
       "      <td>325</td>\n",
       "      <td>36.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">D</th>\n",
       "      <th>F</th>\n",
       "      <td>131</td>\n",
       "      <td>244</td>\n",
       "      <td>375</td>\n",
       "      <td>34.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>138</td>\n",
       "      <td>279</td>\n",
       "      <td>417</td>\n",
       "      <td>33.093525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">E</th>\n",
       "      <th>F</th>\n",
       "      <td>94</td>\n",
       "      <td>299</td>\n",
       "      <td>393</td>\n",
       "      <td>23.918575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>53</td>\n",
       "      <td>138</td>\n",
       "      <td>191</td>\n",
       "      <td>27.748691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">F</th>\n",
       "      <th>F</th>\n",
       "      <td>25</td>\n",
       "      <td>316</td>\n",
       "      <td>341</td>\n",
       "      <td>7.331378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>22</td>\n",
       "      <td>351</td>\n",
       "      <td>373</td>\n",
       "      <td>5.898123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Other</th>\n",
       "      <th>F</th>\n",
       "      <td>937</td>\n",
       "      <td>1549</td>\n",
       "      <td>2486</td>\n",
       "      <td>37.691070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>2227</td>\n",
       "      <td>3211</td>\n",
       "      <td>5438</td>\n",
       "      <td>40.952556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Admission     Accepted  Rejected  Total  Admission Rate\n",
       "Major Gender                                           \n",
       "A     F             89        19    108       82.407407\n",
       "      M            825       313   1138       72.495606\n",
       "B     F             17         8     25       68.000000\n",
       "      M            353       207    560       63.035714\n",
       "C     F            201       392    593       33.895447\n",
       "      M            120       205    325       36.923077\n",
       "D     F            131       244    375       34.933333\n",
       "      M            138       279    417       33.093525\n",
       "E     F             94       299    393       23.918575\n",
       "      M             53       138    191       27.748691\n",
       "F     F             25       316    341        7.331378\n",
       "      M             22       351    373        5.898123\n",
       "Other F            937      1549   2486       37.691070\n",
       "      M           2227      3211   5438       40.952556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run some exploratory data analysis that supports or rejects the results from before (hint: consider confounding variables)\n",
    "department_data = berkeley_data.groupby(['Major', 'Gender', 'Admission']).size().unstack(fill_value=0)\n",
    "department_data['Total'] = department_data.sum(axis=1)\n",
    "department_data['Admission Rate'] = department_data['Accepted'] / department_data['Total'] * 100\n",
    "\n",
    "# Display the results in a pandas dataframe\n",
    "department_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a158c12-81d2-4ef2-b052-5388371c1f79",
   "metadata": {},
   "source": [
    "What are the conclusions after the deeper analysis you conducted?  How did you fix the issue?  Can you abstract away the issue you saw to a general setting and methods to fix this issue in general?\n",
    "\n",
    "In addition, create a plot/visual that shows your findings visually so that it is easier to conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af75e19-92e5-4a8c-a74c-4f10134c4a47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6]),\n",
       " [Text(0, 0, 'A'),\n",
       "  Text(1, 0, 'B'),\n",
       "  Text(2, 0, 'C'),\n",
       "  Text(3, 0, 'D'),\n",
       "  Text(4, 0, 'E'),\n",
       "  Text(5, 0, 'F'),\n",
       "  Text(6, 0, 'Other')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create plot here...\n",
    "department_data.reset_index(inplace=True)\n",
    "pivot_data = department_data.pivot(index=\"Major\", columns='Gender', values='Admission Rate')\n",
    "pivot_data.plot(kind='bar', stacked=False, figsize=(12, 6), width=0.8)\n",
    "plt.title('Admission Rate by Major')\n",
    "plt.ylabel('Admission Rate (%)')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab382281-c56b-44bc-a9a2-2cb7636f7350",
   "metadata": {},
   "source": [
    "Discuss with your neighbors how you can better detect this particular method of data manipulation.  What questions can you ask to better detect this type of data manipulation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f640a-60a6-4567-94db-065131770f1a",
   "metadata": {},
   "source": [
    "# P-Hacking\n",
    "\n",
    "P-hacking refers to the manipulation of data analysis to achieve statistically significant results, often leading to misleading conclusions. This practice undermines the integrity of scientific research by capitalizing on random chance rather than genuine effects.  One can achieve this by:\n",
    "\n",
    "1. **Running Multiple Statistical Tests:**  Conducting numerous statistical analyses on the same dataset and selectively reporting those that yield significant results. For example, one can test 20 different variables against an outcome and only publishing the one with a p-value below 0.05, ignoring the increased likelihood of false positives.\n",
    "\n",
    "2. **Selective Reporting of Variables:**  Measuring multiple outcomes but only reporting those that are statistically significant.  For example, in a clinical trial, assessing various health indicators but only publishing the significant improvement in blood pressure, omitting non-significant results for cholesterol and heart rate.\n",
    "\n",
    "3. **Excluding Outliers Strategically:**  Removing data points that do not support the desired outcome without a valid justification. For example, discarding participants from a study whose responses counter the hypothesized effect, thereby artificially increasing significance.\n",
    "\n",
    "4. **Combining or Splitting Groups:** Altering the grouping of data to achieve significant differences. For example, merging categories or dividing a continuous variable at different points until a significant difference between groups is found.\n",
    "\n",
    "5. **Using Subgroup Analyses:** Conducting multiple analyses on various subgroups and reporting only those with significant findings. For example, analyzing the effect of a drug separately in different age groups and only reporting the age group where the effect was significant.\n",
    "\n",
    "Engaging in p-hacking can lead to false discoveries (i.e. increased likelihood of Type I errors (false positives)) and non-reproducible results.\n",
    "\n",
    "What are other methods of p-hacking that you can think of?\n",
    "\n",
    "## NHANES\n",
    "\n",
    "We will consider the National Health and Nutrition Examination Survey (NHANES) dataset to create a false relationship between caffeine intake and LDL cholesterol (the bad cholesterol).  We do this in steps.\n",
    "\n",
    "1. Load the data.\n",
    "2. Combine data from different files into one pandas dataframe.\n",
    "3. Look at the overall correlation between caffeine intake and LDL cholesterol.\n",
    "4. Manufacture a false correlation by subsampling and running many random samples until we get our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9719b845-de59-43c8-86ec-c18962302daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file paths\n",
    "base_path = 'NHANES_DSET'\n",
    "demographic_file = os.path.join(base_path, 'DEMO_I.xpt')\n",
    "dietary_file = os.path.join(base_path, 'DR1TOT_I.xpt')\n",
    "ldl_file = os.path.join(base_path, 'TRIGLY_I.xpt')\n",
    "tot_chol_file = os.path.join(base_path, 'TCHOL_I.xpt')\n",
    "\n",
    "# load data files\n",
    "demographic_data, meta = pyreadstat.read_xport(demographic_file)\n",
    "dietary_data, _ = pyreadstat.read_xport(dietary_file)\n",
    "ldl_data, _ = pyreadstat.read_xport(ldl_file)\n",
    "chol_data, _ = pyreadstat.read_xport(tot_chol_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "182552a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <th>LBXTR</th>\n",
       "      <th>LBDTRSI</th>\n",
       "      <th>LBDLDL</th>\n",
       "      <th>LBDLDLSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83733.0</td>\n",
       "      <td>54722.343330</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1.660</td>\n",
       "      <td>173.0</td>\n",
       "      <td>4.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83734.0</td>\n",
       "      <td>25471.093699</td>\n",
       "      <td>269.0</td>\n",
       "      <td>3.037</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83736.0</td>\n",
       "      <td>38179.510870</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.531</td>\n",
       "      <td>142.0</td>\n",
       "      <td>3.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83737.0</td>\n",
       "      <td>25800.845631</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.519</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83741.0</td>\n",
       "      <td>108751.289086</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>93687.0</td>\n",
       "      <td>54149.755608</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>93689.0</td>\n",
       "      <td>23526.068487</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.723</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>93695.0</td>\n",
       "      <td>136952.241981</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.881</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>93696.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>93697.0</td>\n",
       "      <td>107064.179240</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.937</td>\n",
       "      <td>127.0</td>\n",
       "      <td>3.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3191 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQN       WTSAF2YR  LBXTR  LBDTRSI  LBDLDL  LBDLDLSI\n",
       "0     83733.0   54722.343330  147.0    1.660   173.0     4.474\n",
       "1     83734.0   25471.093699  269.0    3.037   145.0     3.750\n",
       "2     83736.0   38179.510870   47.0    0.531   142.0     3.672\n",
       "3     83737.0   25800.845631   46.0    0.519   103.0     2.664\n",
       "4     83741.0  108751.289086   68.0    0.768   102.0     2.638\n",
       "...       ...            ...    ...      ...     ...       ...\n",
       "3186  93687.0   54149.755608   50.0    0.565    94.0     2.431\n",
       "3187  93689.0   23526.068487   64.0    0.723    73.0     1.888\n",
       "3188  93695.0  136952.241981   78.0    0.881    56.0     1.448\n",
       "3189  93696.0       0.000000    NaN      NaN     NaN       NaN\n",
       "3190  93697.0  107064.179240   83.0    0.937   127.0     3.284\n",
       "\n",
       "[3191 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d52095e-527c-4bc5-9f72-bbd69d0528da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
      "0  83732.0       9.0       2.0       1.0      62.0       NaN       3.0   \n",
      "1  83733.0       9.0       2.0       1.0      53.0       NaN       3.0   \n",
      "2  83734.0       9.0       2.0       1.0      78.0       NaN       3.0   \n",
      "3  83735.0       9.0       2.0       2.0      56.0       NaN       3.0   \n",
      "4  83736.0       9.0       2.0       2.0      42.0       NaN       4.0   \n",
      "\n",
      "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  DMDHREDU  DMDHRMAR  DMDHSEDU  \\\n",
      "0       3.0       1.0       NaN  ...       5.0       1.0       3.0   \n",
      "1       3.0       1.0       NaN  ...       3.0       3.0       NaN   \n",
      "2       3.0       2.0       NaN  ...       3.0       1.0       3.0   \n",
      "3       3.0       2.0       NaN  ...       5.0       6.0       NaN   \n",
      "4       4.0       2.0       NaN  ...       4.0       3.0       NaN   \n",
      "\n",
      "        WTINT2YR       WTMEC2YR  SDMVPSU  SDMVSTRA  INDHHIN2  INDFMIN2  \\\n",
      "0  134671.370419  135629.507405      1.0     125.0      10.0      10.0   \n",
      "1   24328.560239   25282.425927      1.0     125.0       4.0       4.0   \n",
      "2   12400.008522   12575.838818      1.0     131.0       5.0       5.0   \n",
      "3  102717.995647  102078.634508      1.0     131.0      10.0      10.0   \n",
      "4   17627.674984   18234.736219      2.0     126.0       7.0       7.0   \n",
      "\n",
      "   INDFMPIR  \n",
      "0      4.39  \n",
      "1      1.32  \n",
      "2      1.51  \n",
      "3      5.00  \n",
      "4      1.23  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preview the data\n",
    "print(demographic_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c79fa-b8d4-4f99-888b-c89a07f093c7",
   "metadata": {},
   "source": [
    "Thankfully, all the loaded files have a column for identifying the subjects throughout the files.  This is the column Respondent sequence number (SEQN).  We will combine the data using this column.  Please look at [this webpage](https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2015) to understand where the data is coming from and what the variables mean.  In addition, read about how the data was collected and the demographics of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b21b7a0-6538-4813-8308-b9ad348574a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>DMQMILIZ</th>\n",
       "      <th>DMDBORN4</th>\n",
       "      <th>...</th>\n",
       "      <th>DRD370T</th>\n",
       "      <th>DRD370U</th>\n",
       "      <th>DRD370V</th>\n",
       "      <th>WTSAF2YR</th>\n",
       "      <th>LBXTR</th>\n",
       "      <th>LBDTRSI</th>\n",
       "      <th>LBDLDL</th>\n",
       "      <th>LBDLDLSI</th>\n",
       "      <th>LBXTC</th>\n",
       "      <th>LBDTCSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83733.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54722.343330</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>173.00000</td>\n",
       "      <td>4.474000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>6.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83734.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25471.093699</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>3.037000</td>\n",
       "      <td>145.00000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>5.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83736.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.722163</td>\n",
       "      <td>1.922912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38179.510870</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>142.00000</td>\n",
       "      <td>3.672000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>5.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83737.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25800.845631</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.519000</td>\n",
       "      <td>103.00000</td>\n",
       "      <td>2.664000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>4.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83741.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108751.289086</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>2.638000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>4.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>93687.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.910389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.722163</td>\n",
       "      <td>1.922912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54149.755608</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>94.00000</td>\n",
       "      <td>2.431000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>4.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>93689.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23526.068487</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>73.00000</td>\n",
       "      <td>1.888000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>4.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>93695.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136952.241981</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>1.448000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>3.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>93696.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.722163</td>\n",
       "      <td>1.922912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.603746</td>\n",
       "      <td>1.203566</td>\n",
       "      <td>107.71508</td>\n",
       "      <td>2.785526</td>\n",
       "      <td>184.235693</td>\n",
       "      <td>4.764368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>93697.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107064.179240</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>127.00000</td>\n",
       "      <td>3.284000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>6.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3191 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDRETH1  RIDRETH3  \\\n",
       "0     83733.0       9.0       2.0       1.0      53.0       3.0       3.0   \n",
       "1     83734.0       9.0       2.0       1.0      78.0       3.0       3.0   \n",
       "2     83736.0       9.0       2.0       2.0      42.0       4.0       4.0   \n",
       "3     83737.0       9.0       2.0       2.0      72.0       1.0       1.0   \n",
       "4     83741.0       9.0       2.0       1.0      22.0       4.0       4.0   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "3186  93687.0       9.0       2.0       2.0      16.0       2.0       2.0   \n",
       "3187  93689.0       9.0       2.0       2.0      69.0       1.0       1.0   \n",
       "3188  93695.0       9.0       2.0       2.0      76.0       3.0       3.0   \n",
       "3189  93696.0       9.0       2.0       1.0      26.0       3.0       3.0   \n",
       "3190  93697.0       9.0       2.0       2.0      80.0       3.0       3.0   \n",
       "\n",
       "      RIDEXMON  DMQMILIZ  DMDBORN4  ...   DRD370T   DRD370U  DRD370V  \\\n",
       "0          1.0  2.000000       2.0  ...  1.000000  2.000000      2.0   \n",
       "1          2.0  1.000000       1.0  ...  2.000000  1.000000      2.0   \n",
       "2          2.0  2.000000       1.0  ...  1.722163  1.922912      2.0   \n",
       "3          1.0  2.000000       2.0  ...  1.000000  2.000000      2.0   \n",
       "4          1.0  2.000000       1.0  ...  2.000000  2.000000      2.0   \n",
       "...        ...       ...       ...  ...       ...       ...      ...   \n",
       "3186       2.0  1.910389       1.0  ...  1.722163  1.922912      2.0   \n",
       "3187       1.0  2.000000       1.0  ...  2.000000  1.000000      2.0   \n",
       "3188       2.0  2.000000       1.0  ...  2.000000  2.000000      2.0   \n",
       "3189       1.0  2.000000       1.0  ...  1.722163  1.922912      2.0   \n",
       "3190       2.0  1.000000       1.0  ...  2.000000  2.000000      2.0   \n",
       "\n",
       "           WTSAF2YR       LBXTR   LBDTRSI     LBDLDL  LBDLDLSI       LBXTC  \\\n",
       "0      54722.343330  147.000000  1.660000  173.00000  4.474000  265.000000   \n",
       "1      25471.093699  269.000000  3.037000  145.00000  3.750000  229.000000   \n",
       "2      38179.510870   47.000000  0.531000  142.00000  3.672000  204.000000   \n",
       "3      25800.845631   46.000000  0.519000  103.00000  2.664000  190.000000   \n",
       "4     108751.289086   68.000000  0.768000  102.00000  2.638000  164.000000   \n",
       "...             ...         ...       ...        ...       ...         ...   \n",
       "3186   54149.755608   50.000000  0.565000   94.00000  2.431000  166.000000   \n",
       "3187   23526.068487   64.000000  0.723000   73.00000  1.888000  167.000000   \n",
       "3188  136952.241981   78.000000  0.881000   56.00000  1.448000  140.000000   \n",
       "3189       0.000000  106.603746  1.203566  107.71508  2.785526  184.235693   \n",
       "3190  107064.179240   83.000000  0.937000  127.00000  3.284000  256.000000   \n",
       "\n",
       "       LBDTCSI  \n",
       "0     6.850000  \n",
       "1     5.920000  \n",
       "2     5.280000  \n",
       "3     4.910000  \n",
       "4     4.240000  \n",
       "...        ...  \n",
       "3186  4.290000  \n",
       "3187  4.320000  \n",
       "3188  3.620000  \n",
       "3189  4.764368  \n",
       "3190  6.620000  \n",
       "\n",
       "[3191 rows x 159 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine data\n",
    "combined_data = pd.merge(demographic_data, dietary_data, on=\"SEQN\")\n",
    "combined_data = pd.merge(combined_data, ldl_data, on=\"SEQN\")\n",
    "combined_data = pd.merge(combined_data, chol_data, on=\"SEQN\")\n",
    "# Drop columns with more than 50% missing values\n",
    "combined_data = combined_data.loc[:, combined_data.isnull().mean() < 0.5]\n",
    "# Impute remaining missing values with the column mean\n",
    "combined_data.fillna(combined_data.mean(), inplace=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2319e-62a5-4c81-a26f-430fdd69d5e5",
   "metadata": {},
   "source": [
    "Let us find the true correlation between the caffeine variable and LDL variable.  Note that uncorrelated variables have correlation 0 whilst highly correlated variables have correlation close to 1 (past 0.7) and highly anti-correlated variables have correlation close to -1 (lower than -0.7).  The true correlation and associated p-value are shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b26c5bf-a238-48c2-9618-248652eb040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Correlation: 0.13 | True p-value: 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "# define variables\n",
    "caffeine_variable = 'DR1TCAFF'  # Dietary Caffeine Intake\n",
    "ldl_variable = 'LBDLDL'         # LDL Cholesterol\n",
    "\n",
    "# restrict to subset of only relevant variables\n",
    "subset_data = combined_data[[caffeine_variable, ldl_variable]].dropna()\n",
    "# pearsonr finds correlation and p-value associated with correlation\n",
    "corr, p_value = pearsonr(subset_data[caffeine_variable], subset_data[ldl_variable])\n",
    "\n",
    "print(f\"True Correlation: {corr:.2f} | True p-value: {p_value:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac4c49-7551-4b3f-9636-c5ee98b17da0",
   "metadata": {},
   "source": [
    "We want to show that caffeine and LDL cholesterol is highly correlated.  To do this, we can restrict the data to a \"good\" set that finds high correlation with a good p-value.  We do this in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43a6e71e-6b93-4da1-b1f1-e511cd33ef98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempts so far: 10000 | Best Correlation: 0.68, p-value: 0.0000000429\n",
      "Attempts so far: 20000 | Best Correlation: 0.68, p-value: 0.0000000429\n",
      "Attempts so far: 30000 | Best Correlation: 0.68, p-value: 0.0000000429\n",
      "Attempts so far: 40000 | Best Correlation: 0.68, p-value: 0.0000000429\n",
      "Attempts so far: 50000 | Best Correlation: 0.68, p-value: 0.0000000429\n",
      "Attempts so far: 60000 | Best Correlation: 0.68, p-value: 0.0000000429\n",
      "Attempts so far: 70000 | Best Correlation: 0.68, p-value: 0.0000000429\n",
      "Attempts so far: 80000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 90000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 100000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 110000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 120000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 130000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 140000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 150000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 160000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 170000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 180000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 190000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 200000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 210000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 220000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 230000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 240000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 250000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 260000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 270000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 280000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 290000 | Best Correlation: 0.71, p-value: 0.0000000059\n",
      "Attempts so far: 300000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 310000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 320000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 330000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 340000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 350000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 360000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 370000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 380000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 390000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 400000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 410000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 420000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 430000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 440000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 450000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 460000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 470000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 480000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 490000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 500000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 510000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 520000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 530000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 540000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 550000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 560000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 570000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 580000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 590000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 600000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 610000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 620000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 630000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 640000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 650000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 660000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 670000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 680000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 690000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 700000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 710000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 720000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 730000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 740000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 750000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 760000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 770000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 780000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 790000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 800000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 810000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 820000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 830000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 840000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 850000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 860000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 870000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 880000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 890000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 900000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 910000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 920000 | Best Correlation: 0.74, p-value: 0.0000000009\n",
      "Attempts so far: 930000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "Attempts so far: 940000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "Attempts so far: 950000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "Attempts so far: 960000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "Attempts so far: 970000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "Attempts so far: 980000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "Attempts so far: 990000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "Attempts so far: 1000000 | Best Correlation: 0.77, p-value: 0.0000000000\n",
      "\n",
      "Best Correlation Found After 1000000 Attempts:\n",
      "Correlation: 0.77, p-value: 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "# Initialize tracking variables\n",
    "best_correlation = 0  # Start with a neutral value\n",
    "best_p_value = 1.0\n",
    "best_sample = None\n",
    "sample_size = 50\n",
    "\n",
    "# Run 1000000 random subsets for p-hacking\n",
    "np.random.seed(42)  # For reproducibility\n",
    "attempts = 1000000\n",
    "\n",
    "# set variables for correlation study\n",
    "caffeine_variable = 'DR1TCAFF'  # Dietary Caffeine Intake\n",
    "ldl_variable = 'LBDLDL'         # LDL Cholesterol\n",
    "# restrict to subset of relevant variables\n",
    "subset_data = combined_data[[caffeine_variable, ldl_variable]].dropna()\n",
    "\n",
    "# Run the reduced number of attempts with the fix\n",
    "for i in range(attempts):\n",
    "    # Randomly sample a subset of the data (e.g., 50 data points)\n",
    "    sample = subset_data.sample(sample_size, replace=False)\n",
    "    corr, p_value = pearsonr(sample[caffeine_variable], sample[ldl_variable])\n",
    "\n",
    "    # Track the best correlation with statistical significance\n",
    "    if p_value < 0.05 and abs(corr) > abs(best_correlation):\n",
    "        best_correlation = corr\n",
    "        best_p_value = p_value\n",
    "        best_sample = sample\n",
    "\n",
    "    # Print progress every 10,000 attempts\n",
    "    if (i + 1) % 10000 == 0:\n",
    "        print(f\"Attempts so far: {i + 1} | Best Correlation: {best_correlation:.2f}, p-value: {best_p_value:.10f}\")\n",
    "\n",
    "# Display the best result found\n",
    "if best_sample is not None:\n",
    "    print(f\"\\nBest Correlation Found After {attempts} Attempts:\")\n",
    "    print(f\"Correlation: {best_correlation:.2f}, p-value: {best_p_value:.10f}\")\n",
    "else:\n",
    "    print(f\"No statistically significant result found after {attempts} attempts.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b1dde-db45-483f-9da0-1bab78f45dbd",
   "metadata": {},
   "source": [
    "What are questions one can ask about the data which can help detect p-hacking in a study?  What are aspects that can confound a result?  Here, we maliciously manipulate results to show a particular result, but generally, p-hacking may occur even when a researcher is not trying to p-hack.  What are practices that will combat p-hacking?  What characteristics should a researcher embody to actively combat p-hacking in any studies or data analyses that they conduct?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
